{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMAtjPaTGW9ILVq+J8JrsQ7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/R0onald/Resumidor-Machine-learning-/blob/main/Sumarizador_de_texto_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Resumo de texto com Python***"
      ],
      "metadata": {
        "id": "_MTt_80CXShg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sumarização de Texto é o processo de criação de um resumo de um determinado documento que contém as informações mais importantes do original, cujo objetivo é obter um resumo dos principais pontos do documento, a sumarização de textos também permite diminuir o tempo de leitura, agilizar a busca de informações e obter o máximo de informações possível sobre um assunto"
      ],
      "metadata": {
        "id": "v7Rkt2FgXath"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " - Importando bibliotecas"
      ],
      "metadata": {
        "id": "hLUeI_l3ZUsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6hwEiumd4MG",
        "outputId": "9c2c0e33-4677-45c4-871e-bedd483b916d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UyFQDzJ_XDWW"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import string\n",
        "from heapq import nlargest"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Não precisamos usar muito aprendizado de máquina aqui. Podemos resumir facilmente o texto sem treinar um modelo. Mas ainda assim, precisamos utilizar algum processamento de linguagem natural, para isso utilizarei a biblioteca NLTK em Python."
      ],
      "metadata": {
        "id": "kvOplIEPZSFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from heapq import nlargest\n",
        "import string\n",
        "\n",
        "\n",
        "text = \"\"\"O marketing digital em 2024 está evoluindo\n",
        "          rapidamente, com a personalização de experiências online ganhando\n",
        "          destaque. Estratégias baseadas em dados, inteligência\n",
        "          artificial e realidade aumentada estão moldando campanhas\n",
        "          mais direcionadas, proporcionando interações mais significativas entre marcas\n",
        "          e consumidores. A ascensão das plataformas de áudio e a consolidação de influenciadores\n",
        "          digitais continuam a impactar a paisagem do marketing, enquanto a privacidade dos dados\n",
        "          torna-se uma preocupação central, exigindo abordagens éticas e transparentes. O futuro do MKT digital\n",
        "          é dinâmico, com a adaptação constante a novas tecnologias\n",
        "          e comportamentos do consumidor.\"\"\"\n",
        "\n",
        "# Corrigindo a contagem de pontos finais\n",
        "if text.count(\". \") > 20:\n",
        "    length = int(round(text.count(\". \")/10, 0))\n",
        "else:\n",
        "    length = 1\n",
        "\n",
        "# Removendo pontuações\n",
        "nopunct = [char for char in text if char not in string.punctuation]\n",
        "nopunct = \"\".join(nopunct)\n",
        "\n",
        "# Processando o texto\n",
        "processed_text = [word for word in nopunct.split() if word.lower() not in nltk.corpus.stopwords.words('portuguese')]\n",
        "\n",
        "# Contagem de frequência de palavras\n",
        "word_freq = {}\n",
        "for word in processed_text:\n",
        "    if word not in word_freq:\n",
        "        word_freq[word] = 1\n",
        "    else:\n",
        "        word_freq[word] += 1\n",
        "\n",
        "# Normalizando a frequência das palavras\n",
        "max_freq = max(word_freq.values())\n",
        "for word in word_freq.keys():\n",
        "    word_freq[word] = word_freq[word] / max_freq\n",
        "\n",
        "# Tokenizando e pontuando as sentenças\n",
        "sent_list = nltk.sent_tokenize(text)\n",
        "sent_score = {}\n",
        "\n",
        "# Calculando a pontuação de cada sentença\n",
        "for sent in sent_list:\n",
        "    for word in nltk.word_tokenize(sent.lower()):\n",
        "        if word in word_freq.keys():\n",
        "            if sent not in sent_score.keys():\n",
        "                sent_score[sent] = word_freq[word]\n",
        "            else:\n",
        "                sent_score[sent] += word_freq[word]\n",
        "\n",
        "# Extraindo as sentenças mais importantes\n",
        "summary_sents = nlargest(length, sent_score, key=sent_score.get)\n",
        "summary = \" \".join(summary_sents)\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaHVW2nuh9Fe",
        "outputId": "c873800b-f85f-49cf-d5af-13b56c98f11a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A ascensão das plataformas de áudio e a consolidação de influenciadores\n",
            "          digitais continuam a impactar a paisagem do marketing, enquanto a privacidade dos dados\n",
            "          torna-se uma preocupação central, exigindo abordagens éticas e transparentes.\n"
          ]
        }
      ]
    }
  ]
}